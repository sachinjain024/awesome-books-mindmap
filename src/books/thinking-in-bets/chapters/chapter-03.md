---
number: 3
title: "Bet to Learn: Fielding Outcomes"
meta: Separating luck from skill to extract real lessons from experience
part: LEARNING FROM OUTCOMES
layout: chapter
book: thinking-in-bets
permalink: thinking-in-bets/chapters/chapter-03.html
---

> "The quality of our lives depends on the quality of our decisions. And the quality of our decisions depends on the quality of our learning. And the quality of our learning depends on how well we field our outcomes."
> — Annie Duke

## Outcomes as Learning Signals

Every outcome you experience is a potential data point. The question is whether you're reading it accurately. Most of us are not. We extract the wrong lessons, reinforce the wrong behaviors, and fail to learn the right ones — all because we don't correctly sort outcomes into their component parts: **skill** and **luck**.

This matters enormously because the way we field outcomes determines what we change and what we keep. If we wrongly attribute a bad outcome to bad luck when the real cause was bad process, we'll continue a flawed approach. If we wrongly credit a good outcome to good skill when the real cause was good fortune, we'll repeat a flawed process until the luck runs out.

Getting this right is one of the most valuable cognitive skills a person can develop.

## The Two Great Errors

When outcomes don't go our way, we face two symmetrical temptations — and most people succumb to one of them by default.

### Error 1: Blame Everything on Yourself {.bias-box}

Some people internalize every bad outcome as evidence of personal failure. They learn helplessness and shame rather than accurate lessons. They quit strategies that were actually sound, just unlucky. They lose confidence based on noise rather than signal.

### Error 2: Blame Everything on Luck {.bias-box}

Others externalize every bad outcome as bad luck. They protect their ego at the cost of growth. They learn nothing because, in their account, there's nothing to learn — it was all outside their control. They repeat the same mistakes indefinitely.

Both errors use the same mechanism: they close off inquiry rather than opening it. The honest alternative is harder and more valuable: look at every outcome and ask **how much came from the decision, and how much came from luck?**

## Self-Serving Bias in Action

Self-serving bias is the engine that drives both errors. It's our deep, mostly unconscious tendency to:

- Attribute successes to our own skill, intelligence, or effort
- Attribute failures to bad luck, other people, or circumstances beyond our control

This asymmetry is so pervasive and so automatic that most people don't notice it operating. Researchers have documented it across cultures, professions, and age groups. Students who ace tests credit their preparation; students who fail blame the unfair questions. Managers who lead successful projects take credit; managers who lead failed projects blame their teams, the market, or bad timing.

> "When we make a bad decision, we want to blame the world. When the world goes badly for us, we want to credit ourselves for having foreseen it. In both cases, we're protecting a story about ourselves."
> — Annie Duke

## A Framework for Fielding Outcomes

The antidote to self-serving bias is a deliberate, structured approach to reviewing outcomes. Duke proposes working through a sequence of questions:

### The Outcome Review Process {.tool-box}

**Step 1: What happened?**
Describe the outcome neutrally, without immediately labeling it good or bad.

**Step 2: What did I control?**
Identify the decisions, behaviors, and preparations that were within your control leading up to this outcome.

**Step 3: What was outside my control?**
Identify the factors that influenced the outcome but that you couldn't have reasonably affected — market moves, other people's decisions, weather, random events.

**Step 4: Was my process sound?**
Evaluate the decision-making process itself, independent of the outcome. Did you gather relevant information? Did you consider alternatives? Did you acknowledge uncertainty appropriately?

**Step 5: What would I do differently?**
Only after separating skill from luck should you ask what, if anything, needs to change.

This process is harder and slower than gut reaction. It also produces dramatically better learning.

## The Problem with Hindsight

One of the greatest obstacles to learning from outcomes is **hindsight bias** — the tendency, after an outcome is known, to believe you "knew it all along" or that the outcome was more predictable than it actually was.

Hindsight bias has two damaging effects:

1. **It makes bad outcomes seem more preventable than they were**, leading to excessive blame and guilt.
2. **It makes good outcomes seem more inevitable than they were**, leading to excessive credit and overconfidence.

In both cases, hindsight bias corrupts the lesson. It tells us the world was more predictable than it is, which makes us less prepared for real uncertainty going forward.

### Combating Hindsight Bias {.principle-box}

The best weapon against hindsight bias is **prospective documentation** — writing down your reasoning, your uncertainty, and your expected outcomes *before* you see how things turn out. A decision journal does this systematically. When you review an outcome with your pre-decision thinking in front of you, it's much harder to convince yourself you "knew it all along."

## Learning the Right Amount from Each Outcome

Not all outcomes should update your beliefs equally. The key variable is **how much signal the outcome actually contains**.

- **High signal outcomes** are those where the skill component was dominant. If you prepared extensively for a presentation and it went well, that's meaningful evidence.
- **Low signal outcomes** are those where the luck component was dominant. If your well-prepared presentation went badly because a fire alarm interrupted it, that's not meaningful evidence about your skill.

The challenge is that our emotions don't naturally weight outcomes this way. We feel both equally viscerally. A lucky win produces as much satisfaction as a skilled one; an unlucky loss produces as much pain as a deserved one. Emotional intensity is not a reliable guide to informational content.

Developing the habit of asking "how much luck was in this?" before updating your beliefs is one of the most valuable things you can do to improve your long-term decision-making.

## Key Takeaways

- Outcomes are data, but only if we read them accurately by separating skill (what we controlled) from luck (what we didn't).
- The two great errors: blaming all failures on luck (protecting ego) or blaming all failures on yourself (learning helplessness).
- Self-serving bias systematically distorts outcome attribution in self-flattering directions.
- A structured outcome review process — what happened, what did I control, was my process sound — extracts honest lessons.
- Hindsight bias makes outcomes seem more predictable than they were; prospective journaling is the best defense.
- Update beliefs based on how much signal (skill) the outcome contained, not just on emotional intensity.
